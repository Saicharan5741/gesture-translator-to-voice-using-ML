{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094d6cc1-5aa7-450b-a3c0-edd48037c095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in c:\\users\\saich\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: playsound in c:\\users\\saich\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\saich\\anaconda3\\lib\\site-packages (from gtts) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\saich\\anaconda3\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\saich\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saich\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saich\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saich\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saich\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gtts playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "165749a8-5b07-45a1-9527-ac6485baa9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "No text to speak",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Speech synthesis after finishing showing signs\u001b[39;00m\n\u001b[0;32m     85\u001b[0m language \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 86\u001b[0m myobj \u001b[38;5;241m=\u001b[39m gTTS(text\u001b[38;5;241m=\u001b[39mword, lang\u001b[38;5;241m=\u001b[39mlanguage, slow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     87\u001b[0m speech_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_speech.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m myobj\u001b[38;5;241m.\u001b[39msave(speech_file)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\gtts\\tts.py:133\u001b[0m, in \u001b[0;36mgTTS.__init__\u001b[1;34m(self, text, tld, lang, slow, lang_check, pre_processor_funcs, tokenizer_func, timeout)\u001b[0m\n\u001b[0;32m    130\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, k, v)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Text\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo text to speak\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Translate URL top-level domain\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: No text to speak"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from gtts import gTTS \n",
    "from playsound import playsound\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"STS.h5\")\n",
    "\n",
    "# Define the labels dictionary\n",
    "labels_dict = {i: chr(65+i) for i in range(26)}\n",
    "labels_dict[0] = ' '\n",
    "\n",
    "# Define color for the rectangle around the sign\n",
    "color_dict = (0, 255, 0)\n",
    "\n",
    "# Define image size and threshold value\n",
    "img_size = 128\n",
    "minValue = 70\n",
    "\n",
    "# Initialize video capture\n",
    "source = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize variables for sign detection\n",
    "count = 0\n",
    "word = \"\"\n",
    "prev = \" \"\n",
    "debounce_threshold = 5\n",
    "debounce_counter = 0\n",
    "current_label = None\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(crop_img):\n",
    "    blur = cv2.GaussianBlur(crop_img, (5, 5), 2)\n",
    "    th3 = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    ret, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    resized = cv2.resize(res, (img_size, img_size))\n",
    "    normalized = resized / 255.0\n",
    "    reshaped = np.reshape(normalized, (1, img_size, img_size, 1))\n",
    "    return reshaped\n",
    "\n",
    "# Main loop for sign detection\n",
    "while(True):\n",
    "    ret, img = source.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.rectangle(img, (24, 24), (250, 250), color_dict, 2)\n",
    "    crop_img = gray[24:250, 24:250]\n",
    "\n",
    "    # Preprocess the image\n",
    "    reshaped = preprocess_image(crop_img)\n",
    "\n",
    "    # Predict the sign every 20 frames to reduce computational load\n",
    "    if count % 20 == 0:\n",
    "        result = model.predict(reshaped)\n",
    "        label = np.argmax(result, axis=1)[0]\n",
    "\n",
    "        # Debounce mechanism to avoid flickering between signs\n",
    "        if label == current_label:\n",
    "            debounce_counter += 1\n",
    "            if debounce_counter >= debounce_threshold:\n",
    "                prev = labels_dict[label]\n",
    "                if label != 0:  # Avoid adding space repeatedly\n",
    "                    word += prev\n",
    "        else:\n",
    "            debounce_counter = 0\n",
    "        current_label = label\n",
    "\n",
    "    # Display the current sign and the accumulated word\n",
    "    cv2.putText(img, prev, (24, 14), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2) \n",
    "    cv2.putText(img, word, (275, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (200, 200, 200), 2)\n",
    "    cv2.imshow('LIVE', img)\n",
    "    cv2.imshow(\"Gray\", crop_img)  # Display the grayscale image\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 27:  # Press Esc to exit\n",
    "        break\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# Speech synthesis after finishing showing signs\n",
    "language = 'en'\n",
    "myobj = gTTS(text=word, lang=language, slow=False)\n",
    "speech_file = \"output_speech.mp3\"\n",
    "myobj.save(speech_file)\n",
    "playsound(speech_file)\n",
    "\n",
    "# Cleanup\n",
    "cv2.destroyAllWindows()\n",
    "source.release()\n",
    "os.remove(speech_file)  # Remove the speech file after playing\n",
    "\n",
    "# Print the final word\n",
    "print(f\"The final word is: {word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e77d3-22ea-4366-8bf4-09bf5a4dc74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
